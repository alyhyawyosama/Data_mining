{"cells":[{"cell_type":"markdown","metadata":{},"source":["**This notebook is an exercise in the [Data Cleaning](https://www.kaggle.com/learn/data-cleaning) course.  You can reference the tutorial at [this link](https://www.kaggle.com/alexisbcook/parsing-dates).**\n","\n","---\n"]},{"cell_type":"markdown","metadata":{},"source":["In this exercise, you'll apply what you learned in the **Parsing dates** tutorial.\n","\n","# Setup\n","#### Alyahyawy Osama  < _ >\n","The questions below will give you feedback on your work. Run the following cell to set up the feedback system."]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T18:13:45.128478Z","iopub.status.busy":"2024-01-14T18:13:45.127682Z","iopub.status.idle":"2024-01-14T18:13:47.327737Z","shell.execute_reply":"2024-01-14T18:13:47.326377Z","shell.execute_reply.started":"2024-01-14T18:13:45.128435Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Setup Complete\n"]}],"source":["from learntools.core import binder\n","binder.bind(globals())\n","from learntools.data_cleaning.ex3 import *\n","print(\"Setup Complete\")"]},{"cell_type":"markdown","metadata":{},"source":["# Get our environment set up\n","\n","The first thing we'll need to do is load in the libraries and dataset we'll be using. We'll be working with a dataset containing information on earthquakes that occured between 1965 and 2016."]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T18:14:51.360595Z","iopub.status.busy":"2024-01-14T18:14:51.359721Z","iopub.status.idle":"2024-01-14T18:14:51.470358Z","shell.execute_reply":"2024-01-14T18:14:51.469177Z","shell.execute_reply.started":"2024-01-14T18:14:51.360557Z"},"trusted":true},"outputs":[],"source":["# modules we'll use\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import datetime\n","\n","# read in our data\n","earthquakes = pd.read_csv(\"../input/earthquake-database/database.csv\")\n","\n","# set seed for reproducibility\n","np.random.seed(0)"]},{"cell_type":"markdown","metadata":{},"source":["# 1) Check the data type of our date column\n","\n","You'll be working with the \"Date\" column from the `earthquakes` dataframe.  Investigate this column now: does it look like it contains dates?  What is the dtype of the column?"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T18:25:05.015062Z","iopub.status.busy":"2024-01-14T18:25:05.014065Z","iopub.status.idle":"2024-01-14T18:25:05.024154Z","shell.execute_reply":"2024-01-14T18:25:05.023222Z","shell.execute_reply.started":"2024-01-14T18:25:05.015025Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Timestamp('1965-01-08 00:00:00')"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["# TODO: Your code here!\n","earthquakes.Date.dtype\n","dat = pd.to_datetime(earthquakes.loc[3,'Date'])\n","dat\n","# earthquakes.loc[3378, \"Date\"] = \"02/23/1975\"\n","# earthquakes.loc[7512, \"Date\"] = \"04/28/1985\"\n","# earthquakes.loc[20650, \"Date\"] = \"03/13/2011\"\n"]},{"cell_type":"markdown","metadata":{},"source":["Once you have answered the question above, run the code cell below to get credit for your work."]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T18:15:28.972674Z","iopub.status.busy":"2024-01-14T18:15:28.972245Z","iopub.status.idle":"2024-01-14T18:15:28.982638Z","shell.execute_reply":"2024-01-14T18:15:28.981480Z","shell.execute_reply.started":"2024-01-14T18:15:28.972640Z"},"trusted":true},"outputs":[{"data":{"application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.25, \"interactionType\": 1, \"questionType\": 4, \"questionId\": \"1_CheckDtype\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/markdown":["<span style=\"color:#33cc33\">Correct:</span> \n","\n","The \"Date\" column in the `earthquakes` DataFrame does have dates.  The dtype is \"object\"."],"text/plain":["Correct: \n","\n","The \"Date\" column in the `earthquakes` DataFrame does have dates.  The dtype is \"object\"."]},"metadata":{},"output_type":"display_data"}],"source":["# Check your answer (Run this code cell to receive credit!)\n","q1.check()"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T18:15:44.861230Z","iopub.status.busy":"2024-01-14T18:15:44.860804Z","iopub.status.idle":"2024-01-14T18:15:44.870170Z","shell.execute_reply":"2024-01-14T18:15:44.869003Z","shell.execute_reply.started":"2024-01-14T18:15:44.861195Z"},"trusted":true},"outputs":[{"data":{"application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 2, \"questionType\": 4, \"questionId\": \"1_CheckDtype\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/markdown":["<span style=\"color:#3366cc\">Hint:</span> Use `earthquakes['Date'].head()` to check that the column contains dates and verify that it has dtype \"object\".  You can also use `earthquakes['Date'].dtype` to verify the dtype."],"text/plain":["Hint: Use `earthquakes['Date'].head()` to check that the column contains dates and verify that it has dtype \"object\".  You can also use `earthquakes['Date'].dtype` to verify the dtype."]},"metadata":{},"output_type":"display_data"}],"source":["# Line below will give you a hint\n","q1.hint()"]},{"cell_type":"markdown","metadata":{},"source":["# 2) Convert our date columns to datetime\n","\n","Most of the entries in the \"Date\" column follow the same format: \"month/day/four-digit year\".  However, the entry at index 3378 follows a completely different pattern.  Run the code cell below to see this."]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T18:18:41.350480Z","iopub.status.busy":"2024-01-14T18:18:41.349912Z","iopub.status.idle":"2024-01-14T18:18:41.384305Z","shell.execute_reply":"2024-01-14T18:18:41.383171Z","shell.execute_reply.started":"2024-01-14T18:18:41.350434Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date</th>\n","      <th>Time</th>\n","      <th>Latitude</th>\n","      <th>Longitude</th>\n","      <th>Type</th>\n","      <th>Depth</th>\n","      <th>Depth Error</th>\n","      <th>Depth Seismic Stations</th>\n","      <th>Magnitude</th>\n","      <th>Magnitude Type</th>\n","      <th>...</th>\n","      <th>Magnitude Seismic Stations</th>\n","      <th>Azimuthal Gap</th>\n","      <th>Horizontal Distance</th>\n","      <th>Horizontal Error</th>\n","      <th>Root Mean Square</th>\n","      <th>ID</th>\n","      <th>Source</th>\n","      <th>Location Source</th>\n","      <th>Magnitude Source</th>\n","      <th>Status</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3378</th>\n","      <td>1975-02-23T02:58:41.000Z</td>\n","      <td>1975-02-23T02:58:41.000Z</td>\n","      <td>8.017</td>\n","      <td>124.075</td>\n","      <td>Earthquake</td>\n","      <td>623.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>5.6</td>\n","      <td>MB</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>USP0000A09</td>\n","      <td>US</td>\n","      <td>US</td>\n","      <td>US</td>\n","      <td>Reviewed</td>\n","    </tr>\n","    <tr>\n","      <th>3379</th>\n","      <td>02/23/1975</td>\n","      <td>03:53:36</td>\n","      <td>-21.727</td>\n","      <td>-71.356</td>\n","      <td>Earthquake</td>\n","      <td>33.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>5.6</td>\n","      <td>MB</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>USP0000A0A</td>\n","      <td>US</td>\n","      <td>US</td>\n","      <td>US</td>\n","      <td>Reviewed</td>\n","    </tr>\n","    <tr>\n","      <th>3380</th>\n","      <td>02/23/1975</td>\n","      <td>07:34:11</td>\n","      <td>-10.879</td>\n","      <td>166.667</td>\n","      <td>Earthquake</td>\n","      <td>33.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>5.5</td>\n","      <td>MS</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>USP0000A0C</td>\n","      <td>US</td>\n","      <td>US</td>\n","      <td>US</td>\n","      <td>Reviewed</td>\n","    </tr>\n","    <tr>\n","      <th>3381</th>\n","      <td>02/25/1975</td>\n","      <td>05:20:05</td>\n","      <td>-7.388</td>\n","      <td>149.798</td>\n","      <td>Earthquake</td>\n","      <td>33.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>5.5</td>\n","      <td>MB</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>USP0000A12</td>\n","      <td>US</td>\n","      <td>US</td>\n","      <td>US</td>\n","      <td>Reviewed</td>\n","    </tr>\n","    <tr>\n","      <th>3382</th>\n","      <td>02/26/1975</td>\n","      <td>04:48:55</td>\n","      <td>85.047</td>\n","      <td>97.969</td>\n","      <td>Earthquake</td>\n","      <td>33.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>5.6</td>\n","      <td>MS</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>USP0000A1H</td>\n","      <td>US</td>\n","      <td>US</td>\n","      <td>US</td>\n","      <td>Reviewed</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 21 columns</p>\n","</div>"],"text/plain":["                          Date                      Time  Latitude  Longitude  \\\n","3378  1975-02-23T02:58:41.000Z  1975-02-23T02:58:41.000Z     8.017    124.075   \n","3379                02/23/1975                  03:53:36   -21.727    -71.356   \n","3380                02/23/1975                  07:34:11   -10.879    166.667   \n","3381                02/25/1975                  05:20:05    -7.388    149.798   \n","3382                02/26/1975                  04:48:55    85.047     97.969   \n","\n","            Type  Depth  Depth Error  Depth Seismic Stations  Magnitude  \\\n","3378  Earthquake  623.0          NaN                     NaN        5.6   \n","3379  Earthquake   33.0          NaN                     NaN        5.6   \n","3380  Earthquake   33.0          NaN                     NaN        5.5   \n","3381  Earthquake   33.0          NaN                     NaN        5.5   \n","3382  Earthquake   33.0          NaN                     NaN        5.6   \n","\n","     Magnitude Type  ...  Magnitude Seismic Stations  Azimuthal Gap  \\\n","3378             MB  ...                         NaN            NaN   \n","3379             MB  ...                         NaN            NaN   \n","3380             MS  ...                         NaN            NaN   \n","3381             MB  ...                         NaN            NaN   \n","3382             MS  ...                         NaN            NaN   \n","\n","      Horizontal Distance  Horizontal Error  Root Mean Square          ID  \\\n","3378                  NaN               NaN               NaN  USP0000A09   \n","3379                  NaN               NaN               NaN  USP0000A0A   \n","3380                  NaN               NaN               NaN  USP0000A0C   \n","3381                  NaN               NaN               NaN  USP0000A12   \n","3382                  NaN               NaN               NaN  USP0000A1H   \n","\n","     Source Location Source Magnitude Source    Status  \n","3378     US              US               US  Reviewed  \n","3379     US              US               US  Reviewed  \n","3380     US              US               US  Reviewed  \n","3381     US              US               US  Reviewed  \n","3382     US              US               US  Reviewed  \n","\n","[5 rows x 21 columns]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["earthquakes[3378:3383]\n","# pd.to_datetime(earthquakes, format=\"%m/%d/%y\")"]},{"cell_type":"markdown","metadata":{},"source":["This does appear to be an issue with data entry: ideally, all entries in the column have the same format.  We can get an idea of how widespread this issue is by checking the length of each entry in the \"Date\" column."]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T18:19:02.996780Z","iopub.status.busy":"2024-01-14T18:19:02.996382Z","iopub.status.idle":"2024-01-14T18:19:03.026309Z","shell.execute_reply":"2024-01-14T18:19:03.025039Z","shell.execute_reply.started":"2024-01-14T18:19:02.996732Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Date\n","10    23409\n","24        3\n","Name: count, dtype: int64"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["date_lengths = earthquakes.Date.str.len()\n","date_lengths.value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["Looks like there are two more rows that has a date in a different format.  Run the code cell below to obtain the indices corresponding to those rows and print the data."]},{"cell_type":"markdown","metadata":{},"source":["Given all of this information, it's your turn to create a new column \"date_parsed\" in the `earthquakes` dataset that has correctly parsed dates in it.  \n","\n","**Note**: When completing this problem, you are allowed to (but are not required to) amend the entries in the \"Date\" and \"Time\" columns.  Do not remove any rows from the dataset."]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T18:21:41.086002Z","iopub.status.busy":"2024-01-14T18:21:41.085604Z","iopub.status.idle":"2024-01-14T18:21:41.115727Z","shell.execute_reply":"2024-01-14T18:21:41.114610Z","shell.execute_reply.started":"2024-01-14T18:21:41.085972Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Indices with corrupted data: [ 3378  7512 20650]\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date</th>\n","      <th>Time</th>\n","      <th>Latitude</th>\n","      <th>Longitude</th>\n","      <th>Type</th>\n","      <th>Depth</th>\n","      <th>Depth Error</th>\n","      <th>Depth Seismic Stations</th>\n","      <th>Magnitude</th>\n","      <th>Magnitude Type</th>\n","      <th>...</th>\n","      <th>Magnitude Seismic Stations</th>\n","      <th>Azimuthal Gap</th>\n","      <th>Horizontal Distance</th>\n","      <th>Horizontal Error</th>\n","      <th>Root Mean Square</th>\n","      <th>ID</th>\n","      <th>Source</th>\n","      <th>Location Source</th>\n","      <th>Magnitude Source</th>\n","      <th>Status</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3378</th>\n","      <td>02/23/1975</td>\n","      <td>1975-02-23T02:58:41.000Z</td>\n","      <td>8.017</td>\n","      <td>124.075</td>\n","      <td>Earthquake</td>\n","      <td>623.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>5.6</td>\n","      <td>MB</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>USP0000A09</td>\n","      <td>US</td>\n","      <td>US</td>\n","      <td>US</td>\n","      <td>Reviewed</td>\n","    </tr>\n","    <tr>\n","      <th>7512</th>\n","      <td>04/28/1985</td>\n","      <td>1985-04-28T02:53:41.530Z</td>\n","      <td>-32.998</td>\n","      <td>-71.766</td>\n","      <td>Earthquake</td>\n","      <td>33.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>5.6</td>\n","      <td>MW</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.30</td>\n","      <td>USP0002E81</td>\n","      <td>US</td>\n","      <td>US</td>\n","      <td>HRV</td>\n","      <td>Reviewed</td>\n","    </tr>\n","    <tr>\n","      <th>20650</th>\n","      <td>03/13/2011</td>\n","      <td>2011-03-13T02:23:34.520Z</td>\n","      <td>36.344</td>\n","      <td>142.344</td>\n","      <td>Earthquake</td>\n","      <td>10.1</td>\n","      <td>13.9</td>\n","      <td>289.0</td>\n","      <td>5.8</td>\n","      <td>MWC</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>32.3</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.06</td>\n","      <td>USP000HWQP</td>\n","      <td>US</td>\n","      <td>US</td>\n","      <td>GCMT</td>\n","      <td>Reviewed</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3 rows × 21 columns</p>\n","</div>"],"text/plain":["             Date                      Time  Latitude  Longitude        Type  \\\n","3378   02/23/1975  1975-02-23T02:58:41.000Z     8.017    124.075  Earthquake   \n","7512   04/28/1985  1985-04-28T02:53:41.530Z   -32.998    -71.766  Earthquake   \n","20650  03/13/2011  2011-03-13T02:23:34.520Z    36.344    142.344  Earthquake   \n","\n","       Depth  Depth Error  Depth Seismic Stations  Magnitude Magnitude Type  \\\n","3378   623.0          NaN                     NaN        5.6             MB   \n","7512    33.0          NaN                     NaN        5.6             MW   \n","20650   10.1         13.9                   289.0        5.8            MWC   \n","\n","       ...  Magnitude Seismic Stations  Azimuthal Gap  Horizontal Distance  \\\n","3378   ...                         NaN            NaN                  NaN   \n","7512   ...                         NaN            NaN                  NaN   \n","20650  ...                         NaN           32.3                  NaN   \n","\n","       Horizontal Error  Root Mean Square          ID Source Location Source  \\\n","3378                NaN               NaN  USP0000A09     US              US   \n","7512                NaN              1.30  USP0002E81     US              US   \n","20650               NaN              1.06  USP000HWQP     US              US   \n","\n","      Magnitude Source    Status  \n","3378                US  Reviewed  \n","7512               HRV  Reviewed  \n","20650             GCMT  Reviewed  \n","\n","[3 rows x 21 columns]"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["indices = np.where([date_lengths == 24])[1]\n","print('Indices with corrupted data:', indices)\n","earthquakes.loc[indices]"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T18:31:52.063575Z","iopub.status.busy":"2024-01-14T18:31:52.062783Z","iopub.status.idle":"2024-01-14T18:31:52.155381Z","shell.execute_reply":"2024-01-14T18:31:52.154050Z","shell.execute_reply.started":"2024-01-14T18:31:52.063539Z"},"trusted":true},"outputs":[{"data":{"application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.25, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"2_ConvertToDatetime\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/markdown":["<span style=\"color:#33cc33\">Correct</span>"],"text/plain":["Correct"]},"metadata":{},"output_type":"display_data"}],"source":["# TODO: Your code here\n","earthquakes.loc[3378, \"Date\"] = \"02/23/1975\"\n","earthquakes.loc[7512, \"Date\"] = \"04/28/1985\"\n","earthquakes.loc[20650, \"Date\"] = \"03/13/2011\"\n","earthquakes['date_parsed'] = pd.to_datetime(earthquakes['Date'], format=\"%m/%d/%Y\")\n","\n","# Check your answer\n","q2.check()"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T18:21:04.990030Z","iopub.status.busy":"2024-01-14T18:21:04.989613Z","iopub.status.idle":"2024-01-14T18:21:04.994555Z","shell.execute_reply":"2024-01-14T18:21:04.993531Z","shell.execute_reply.started":"2024-01-14T18:21:04.989999Z"},"trusted":true},"outputs":[],"source":["# Lines below will give you a hint or solution code\n","# q2.hint()\n","# q2.solution()"]},{"cell_type":"markdown","metadata":{},"source":["# 3) Select the day of the month\n","\n","Create a Pandas Series `day_of_month_earthquakes` containing the day of the month from the \"date_parsed\" column."]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T18:32:10.488449Z","iopub.status.busy":"2024-01-14T18:32:10.487974Z","iopub.status.idle":"2024-01-14T18:32:10.501919Z","shell.execute_reply":"2024-01-14T18:32:10.500811Z","shell.execute_reply.started":"2024-01-14T18:32:10.488409Z"},"trusted":true},"outputs":[{"data":{"application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.25, \"interactionType\": 1, \"questionType\": 1, \"questionId\": \"3_DayOfMonth\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/markdown":["<span style=\"color:#33cc33\">Correct</span>"],"text/plain":["Correct"]},"metadata":{},"output_type":"display_data"}],"source":["# try to get the day of the month from the date column\n","day_of_month_earthquakes = earthquakes['date_parsed'].dt.day\n","# Check your answer\n","q3.check()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Lines below will give you a hint or solution code\n","#q3.hint()\n","#q3.solution()"]},{"cell_type":"markdown","metadata":{},"source":["# 4) Plot the day of the month to check the date parsing\n","\n","Plot the days of the month from your earthquake dataset."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# TODO: Your code here!\n","day_of_month_earthquakes = day_of_month_earthquakes.dropna()\n","\n","# plot the day of the month\n","sns.distplot(day_of_month_earthquakes, kde=False, bins=31)"]},{"cell_type":"markdown","metadata":{},"source":["Does the graph make sense to you?"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"source":["# Check your answer (Run this code cell to receive credit!)\n","q4.check()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Line below will give you a hint\n","#q4.hint()"]},{"cell_type":"markdown","metadata":{},"source":["# (Optional) Bonus Challenge\n","\n","For an extra challenge, you'll work with a [Smithsonian dataset](https://www.kaggle.com/smithsonian/volcanic-eruptions) that documents Earth's volcanoes and their eruptive history over the past 10,000 years \n","\n","Run the next code cell to load the data."]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"source":["volcanos = pd.read_csv(\"../input/volcanic-eruptions/database.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["Try parsing the column \"Last Known Eruption\" from the `volcanos` dataframe. This column contains a mixture of text (\"Unknown\") and years both before the common era (BCE, also known as BC) and in the common era (CE, also known as AD)."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["volcanos['Last Known Eruption'].sample(5)"]},{"cell_type":"markdown","metadata":{},"source":["# (Optional) More practice\n","\n","If you're interested in graphing time series, [check out this tutorial](https://www.kaggle.com/residentmario/time-series-plotting-optional).\n","\n","You can also look into passing columns that you know have dates in them  the `parse_dates` argument in `read_csv`. (The documention [is here](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html).) Do note that this method can be very slow, but depending on your needs it may sometimes be handy to use.\n","\n","# Keep going\n","\n","In the next lesson, learn how to [**work with character encodings**](https://www.kaggle.com/alexisbcook/character-encodings)."]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","\n","\n","\n","*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/data-cleaning/discussion) to chat with other learners.*"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":705,"sourceId":1325,"sourceType":"datasetVersion"},{"datasetId":732,"sourceId":1360,"sourceType":"datasetVersion"}],"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
